<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Qa | The long way through Software Craftsmanship]]></title>
  <link href="http://alvarogarcia7.github.io/blog/categories/qa/atom.xml" rel="self"/>
  <link href="http://alvarogarcia7.github.io/"/>
  <updated>2016-04-17T21:54:59+00:00</updated>
  <id>http://alvarogarcia7.github.io/</id>
  <author>
    <name><![CDATA[alvaro garcia]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Internal Training: QA &amp; How to Test]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test/"/>
    <updated>2015-05-18T20:20:09+00:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test</id>
    <content type="html"><![CDATA[<p>At a client, we&rsquo;ve done today an internal training on &ldquo;QA &amp; how to test&rdquo;. In it, the most skilled person with the QA role in the dev team has explained to us some techniques and concepts for testing</p>

<h2>My notes</h2>

<p>Verification vs validation: building the product right vs building the right product.</p>

<h3>Principles</h3>

<p>Extracted from <a href="http://www.istqb.org/">ISTQB</a>:</p>

<ul>
<li>testing shows presence of defects</li>
<li>exhaustive testing is impossible</li>
<li>early testing is better than later testing</li>
<li>defect clustering: areas with bigger defect ratio or more critical, etc should be tested more thoroughly</li>
<li>pesticide paradox</li>
<li>testing is context-dependent</li>
<li>absence of errors fallacy: the absence of defects does not imply perfect software. There are also problems with validation.</li>
</ul>


<h3>Techniques</h3>

<h4>People-based</h4>

<ul>
<li>bug bashes: e.g., time-constrained</li>
<li>subject-matter expert testing</li>
<li>eat your own dogfood</li>
<li>others</li>
</ul>


<h4>Activity-based</h4>

<ul>
<li>regression</li>
<li>scripted (manual)</li>
<li>smoke</li>
<li>exploratory</li>
<li>installation</li>
<li>load</li>
<li>long sequence</li>
<li>performance</li>
</ul>


<h4>Coverage-based</h4>

<ul>
<li>menu tour: exploration based on menus (especially on websites)</li>
<li>functional and system testing</li>
<li>integration</li>
<li>logic</li>
<li>state-based</li>
</ul>


<h4>Requirements-based</h4>

<ul>
<li>Equivalence partitioning: examples in the same set are considered equivalent</li>
<li>Boundary based: there are interesting examples around and on the boundaries</li>
<li>Decision tables: truth table</li>
<li>State transition tables: state diagram</li>
</ul>


<h4>Risk-based</h4>

<ul>
<li>make a prioritized list: probability and impact</li>
<li>perform testing exploring each risk</li>
<li>after a risk disappears, another opens. Adjust your test effort to stay focused on the current crop</li>
</ul>


<h4>Use case tests</h4>

<ul>
<li>use case: a common case that represents one of your customer&rsquo;s cases</li>
<li>use busines language</li>
</ul>


<h4>Structure-based</h4>

<ul>
<li>test coverage is different than code coverage</li>
<li>test coverage is based on decision tables</li>
</ul>


<h4>Defining testing priorities</h4>

<ul>
<li>customer and contractual requirements</li>
<li>regulatory</li>
<li>experience-based</li>
<li>&ldquo;Best representative&rdquo;</li>
</ul>

]]></content>
  </entry>
  
</feed>
