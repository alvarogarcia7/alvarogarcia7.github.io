<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Training | The long way through Software Craftsmanship]]></title>
  <link href="http://alvarogarcia7.github.io/blog/categories/training/atom.xml" rel="self"/>
  <link href="http://alvarogarcia7.github.io/"/>
  <updated>2015-07-30T23:43:41+02:00</updated>
  <id>http://alvarogarcia7.github.io/</id>
  <author>
    <name><![CDATA[alvaro garcia]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Brown-bag Session: Refactoring Legacy Code]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/07/01/brownbag-session-refactoring-legacy-code/"/>
    <updated>2015-07-01T13:18:28+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/07/01/brownbag-session-refactoring-legacy-code</id>
    <content type="html"><![CDATA[<p>Today I have done a brown bag session about refactoring legacy code. It includes:</p>

<ul>
<li>legacy code definition. There is no agreement about this in the team.</li>
<li>the legacy code change algorithm (source is Feathers, Working effectively with legacy code). Plus an example about it.</li>
<li>working with legacy code</li>
<li>experience with it.</li>
</ul>


<p>The slides are available <a href="../../../../uploads/refactoring-legacy-code-slides.pdf">here</a> (PDF format)</p>

<p>We also did a practical session, whose experience report is <a href="../../../../2015/06/23/brown-bag-session-refactoring-legacy-code/">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Brown-bag Session: Refactoring Legacy Code]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/23/brown-bag-session-refactoring-legacy-code/"/>
    <updated>2015-06-23T19:19:28+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/23/brown-bag-session-refactoring-legacy-code</id>
    <content type="html"><![CDATA[<p>Today I have facilitated a brown bag session about refactoring legacy code applications, as this is the case with one of the applications we maintain and add new features to.</p>

<p>The contents of the session:</p>

<ul>
<li>Briefly exposing the problem to the team, me taking the role of the Product Owner (PO)</li>
<li>Ask the dev team to add an easy feature</li>
<li>Do it without tests, as it was so simple that they thought they could do it (using mob programming)</li>
<li>Ask if they were satisfied by the patch / fix. Answer was yes.</li>
<li>Point out that there are regressions in the few lines of the patch</li>
<li>Repeat the session, starting with adding tests to guarantee the behavior is preserved  (using mob programming)</li>
<li>Explain the technique of the golden master</li>
<li>Some more programming, until they start to see the light at the end of the tunnel</li>
<li>Small retrospective, including:

<ul>
<li>asking them their feelings when dealing with legacy code. The contents of this is pretty similar to the concepts that appear in the retrospectives, when talking about the legacy project / submodule.</li>
<li>what could I improve as facilitator or for the structure of the session</li>
</ul>
</li>
</ul>


<p>The repo can be found <a href="https://github.com/alvarogarcia7/trivia-kata-spike">here</a>.</p>

<p>I prepared a small script:</p>

<pre><code class="bash">while test true; do
  git add --all;
  git commit --all -m "save process - uknown state";
  sleep 120;
done;
</code></pre>

<p>that saves the process and the progress, without disturbing the attendees. This allows you to follow the progress without any distraction. This idea was taken from a similar one from  <a href="http://twitter.com/@xav1uzz">Xavi Gost</a> <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>This same idea was also cited by someone else, if I recall correctly by Sandro Mancuso, saying that it would be a good idea to have a background git repository while working. IntelliJ IDEA already does something similar (and saves the events, e.g., when the tests are run, either red or green)</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Cannot find the source, it was about having a script to commit automatically each time you run the tests; if it was red while refactoring, it would do git checkout (to revert); Was related to the noFlopSquad<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Brown-bag Session: Docker]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/16/brown-bag-session-docker/"/>
    <updated>2015-06-16T18:52:28+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/16/brown-bag-session-docker</id>
    <content type="html"><![CDATA[<p>Today we have done a brown bag session about Docker. One of the team members explained to us the latest news, topics and how tos, including:</p>

<ul>
<li>the difference between a container and an image</li>
<li>diffing image contents</li>
<li>AUFS (Another Union FS)</li>
<li>persistent vs non-persistent (volatile) filesystems</li>
<li>running CMD and other commands on the instance</li>
<li>problems of running with permission = root (or its group)</li>
<li>downsides of it</li>
<li>how to compare it with a virtual machine</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Internal Training: BPM: Process and Tools for Developers]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/02/internal-training-bpm-tool-and-process/"/>
    <updated>2015-06-02T22:20:09+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/02/internal-training-bpm-tool-and-process</id>
    <content type="html"><![CDATA[<p>At a client, I&rsquo;ve presented today an internal training on &ldquo;BPM: Process and tools for developers&rdquo;</p>

<p>In it, we have introduced the BPM concept and the main ideas in Activiti BPM.</p>

<p>Also techniques for hotswapping processes, tips and how-tos.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Internal Training: QA &amp; How to Test]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test/"/>
    <updated>2015-05-18T22:20:09+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test</id>
    <content type="html"><![CDATA[<p>At a client, we&rsquo;ve done today an internal training on &ldquo;QA &amp; how to test&rdquo;. In it, the most skilled person with the QA role in the dev team has explained to us some techniques and concepts for testing</p>

<h2>My notes</h2>

<p>Verification vs validation: building the product right vs building the right product.</p>

<h3>Principles</h3>

<p>Extracted from <a href="http://www.istqb.org/">ISTQB</a>:</p>

<ul>
<li>testing shows presence of defects</li>
<li>exhaustive testing is impossible</li>
<li>early testing is better than later testing</li>
<li>defect clustering: areas with bigger defect ratio or more critical, etc should be tested more thoroughly</li>
<li>pesticide paradox</li>
<li>testing is context-dependent</li>
<li>absence of errors fallacy: the absence of defects does not imply perfect software. There are also problems with validation.</li>
</ul>


<h3>Techniques</h3>

<h4>People-based</h4>

<ul>
<li>bug bashes: e.g., time-constrained</li>
<li>subject-matter expert testing</li>
<li>eat your own dogfood</li>
<li>others</li>
</ul>


<h4>Activity-based</h4>

<ul>
<li>regression</li>
<li>scripted (manual)</li>
<li>smoke</li>
<li>exploratory</li>
<li>installation</li>
<li>load</li>
<li>long sequence</li>
<li>performance</li>
</ul>


<h4>Coverage-based</h4>

<ul>
<li>menu tour: exploration based on menus (especially on websites)</li>
<li>functional and system testing</li>
<li>integration</li>
<li>logic</li>
<li>state-based</li>
</ul>


<h4>Requirements-based</h4>

<ul>
<li>Equivalence partitioning: examples in the same set are considered equivalent</li>
<li>Boundary based: there are interesting examples around and on the boundaries</li>
<li>Decision tables: truth table</li>
<li>State transition tables: state diagram</li>
</ul>


<h4>Risk-based</h4>

<ul>
<li>make a prioritized list: probability and impact</li>
<li>perform testing exploring each risk</li>
<li>after a risk disappears, another opens. Adjust your test effort to stay focused on the current crop</li>
</ul>


<h4>Use case tests</h4>

<ul>
<li>use case: a common case that represents one of your customer&rsquo;s cases</li>
<li>use busines language</li>
</ul>


<h4>Structure-based</h4>

<ul>
<li>test coverage is different than code coverage</li>
<li>test coverage is based on decision tables</li>
</ul>


<h4>Defining testing priorities</h4>

<ul>
<li>customer and contractual requirements</li>
<li>regulatory</li>
<li>experience-based</li>
<li>&ldquo;Best representative&rdquo;</li>
</ul>

]]></content>
  </entry>
  
</feed>
