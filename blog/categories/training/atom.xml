<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Training | The long way through Software Craftsmanship]]></title>
  <link href="http://alvarogarcia7.github.io/blog/categories/training/atom.xml" rel="self"/>
  <link href="http://alvarogarcia7.github.io/"/>
  <updated>2015-06-29T00:17:06+02:00</updated>
  <id>http://alvarogarcia7.github.io/</id>
  <author>
    <name><![CDATA[alvaro garcia]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Brown-bag Session: Refactoring Legacy Code]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/23/brown-bag-session-refactoring-legacy-code/"/>
    <updated>2015-06-23T19:19:28+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/23/brown-bag-session-refactoring-legacy-code</id>
    <content type="html"><![CDATA[<p>Today I have facilitated a brown bag session about refactoring legacy code applications, as this is the case with one of the applications we maintain and add new features to.</p>

<p>The contents of the session:</p>

<ul>
<li>Briefly exposing the problem to the team, me taking the role of the Product Owner (PO)</li>
<li>Ask the dev team to add an easy feature</li>
<li>Do it without tests, as it was so simple that they thought they could do it (using mob programming)</li>
<li>Ask if they were satisfied by the patch / fix. Answer was yes.</li>
<li>Point out that there are regressions in the few lines of the patch</li>
<li>Repeat the session, starting with adding tests to guarantee the behavior is preserved  (using mob programming)</li>
<li>Explain the technique of the golden master</li>
<li>Some more programming, until they start to see the light at the end of the tunnel</li>
<li>Small retrospective, including:

<ul>
<li>asking them their feelings when dealing with legacy code. The contents of this is pretty similar to the concepts that appear in the retrospectives, when talking about the legacy project / submodule.</li>
<li>what could I improve as facilitator or for the structure of the session</li>
</ul>
</li>
</ul>


<p>The repo can be found <a href="https://github.com/alvarogarcia7/trivia-kata-spike">here</a>.</p>

<p>I prepared a small script:</p>

<pre><code class="bash">while test true; do
  git add --all;
  git commit --all -m "save process - uknown state";
  sleep 120;
done;
</code></pre>

<p>that saves the process and the progress, without disturbing the attendees. This allows you to follow the progress without any distraction. This idea was taken from a similar one from  <a href="http://twitter.com/@xav1uzz">Xavi Gost</a> <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>This same idea was also cited by someone else, if I recall correctly by Sandro Mancuso, saying that it would be a good idea to have a background git repository while working. IntelliJ IDEA already does something similar (and saves the events, e.g., when the tests are run, either red or green)</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Cannot find the source, it was about having a script to commit automatically each time you run the tests; if it was red while refactoring, it would do git checkout (to revert); Was related to the noFlopSquad<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Brown-bag Session: Maven]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/16/brown-bag-session-docker/"/>
    <updated>2015-06-16T18:52:28+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/16/brown-bag-session-docker</id>
    <content type="html"><![CDATA[<p>Today we have done a brown bag session about Docker. One of the team members explained to us the latest news, topics and how tos, including:</p>

<ul>
<li>the difference between a container and an image</li>
<li>diffing image contents</li>
<li>AUFS (Another Union FS)</li>
<li>persistent vs non-persistent (volatile) filesystems</li>
<li>running CMD and other commands on the instance</li>
<li>problems of running with permission = root (or its group)</li>
<li>downsides of it</li>
<li>how to compare it with a virtual machine</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Internal Training: BPM: Process and Tools for Developers]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/06/02/internal-training-bpm-tool-and-process/"/>
    <updated>2015-06-02T22:20:09+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/06/02/internal-training-bpm-tool-and-process</id>
    <content type="html"><![CDATA[<p>At a client, I&rsquo;ve presented today an internal training on &ldquo;BPM: Process and tools for developers&rdquo;</p>

<p>In it, we have introduced the BPM concept and the main ideas in Activiti BPM.</p>

<p>Also techniques for hotswapping processes, tips and how-tos.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Internal Training: QA &amp; How to Test]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test/"/>
    <updated>2015-05-18T22:20:09+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/05/18/internal-training-qa-and-how-to-test</id>
    <content type="html"><![CDATA[<p>At a client, we&rsquo;ve done today an internal training on &ldquo;QA &amp; how to test&rdquo;. In it, the most skilled person with the QA role in the dev team has explained to us some techniques and concepts for testing</p>

<h2>My notes</h2>

<p>Verification vs validation: building the product right vs building the right product.</p>

<h3>Principles</h3>

<p>Extracted from <a href="http://www.istqb.org/">ISTQB</a>:</p>

<ul>
<li>testing shows presence of defects</li>
<li>exhaustive testing is impossible</li>
<li>early testing is better than later testing</li>
<li>defect clustering: areas with bigger defect ratio or more critical, etc should be tested more thoroughly</li>
<li>pesticide paradox</li>
<li>testing is context-dependent</li>
<li>absence of errors fallacy: the absence of defects does not imply perfect software. There are also problems with validation.</li>
</ul>


<h3>Techniques</h3>

<h4>People-based</h4>

<ul>
<li>bug bashes: e.g., time-constrained</li>
<li>subject-matter expert testing</li>
<li>eat your own dogfood</li>
<li>others</li>
</ul>


<h4>Activity-based</h4>

<ul>
<li>regression</li>
<li>scripted (manual)</li>
<li>smoke</li>
<li>exploratory</li>
<li>installation</li>
<li>load</li>
<li>long sequence</li>
<li>performance</li>
</ul>


<h4>Coverage-based</h4>

<ul>
<li>menu tour: exploration based on menus (especially on websites)</li>
<li>functional and system testing</li>
<li>integration</li>
<li>logic</li>
<li>state-based</li>
</ul>


<h4>Requirements-based</h4>

<ul>
<li>Equivalence partitioning: examples in the same set are considered equivalent</li>
<li>Boundary based: there are interesting examples around and on the boundaries</li>
<li>Decision tables: truth table</li>
<li>State transition tables: state diagram</li>
</ul>


<h4>Risk-based</h4>

<ul>
<li>make a prioritized list: probability and impact</li>
<li>perform testing exploring each risk</li>
<li>after a risk disappears, another opens. Adjust your test effort to stay focused on the current crop</li>
</ul>


<h4>Use case tests</h4>

<ul>
<li>use case: a common case that represents one of your customer&rsquo;s cases</li>
<li>use busines language</li>
</ul>


<h4>Structure-based</h4>

<ul>
<li>test coverage is different than code coverage</li>
<li>test coverage is based on decision tables</li>
</ul>


<h4>Defining testing priorities</h4>

<ul>
<li>customer and contractual requirements</li>
<li>regulatory</li>
<li>experience-based</li>
<li>&ldquo;Best representative&rdquo;</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Internal Training: Testing Is Hard - Just Do It]]></title>
    <link href="http://alvarogarcia7.github.io/blog/2015/05/05/internal-training-testing-is-hard-just-do-it/"/>
    <updated>2015-05-05T23:00:17+02:00</updated>
    <id>http://alvarogarcia7.github.io/blog/2015/05/05/internal-training-testing-is-hard-just-do-it</id>
    <content type="html"><![CDATA[<p>At a client, last week I&rsquo;ve organized an internal training, in the form of a discussion about this article: <a href="http://davidsouther.com/#/posts/2013/10/30/testing-its-hard-just-do-it/">Testing is hard - just do it</a></p>

<h2>Our thoughts</h2>

<blockquote><p>When a bug is found, prove it exists with a test</p></blockquote>

<p>This immediately reduces defect rate: the same regression cannot be introduced again</p>

<blockquote><p> fix a bug a second time</p></blockquote>

<p>If fixing a bug (having defects in your code) was &lsquo;waste&rsquo;, as defined by lean methodologies, it also is wast fixing it for the following times</p>

<blockquote><p>testing requires discipline</p></blockquote>

<p>Agree. See quote by Larry Wall (this same article)</p>

<blockquote><p>[Three requirements for a good test suite]:</p>

<ol>
<li>The tests need to be easier to write</li>
<li>The test suite must run, and pass, before any code is allowed out the door</li>
<li>Support from the project&rsquo;s leadership</li>
</ol>
</blockquote>

<p>Agree.</p>

<blockquote><p>Programming is like drawing water from a well</p></blockquote>

<p>Good analogy</p>

<blockquote><p>I&rsquo;m going to assume you are smarter than me [&hellip;]</p></blockquote>

<p>This is related to &lsquo;doing clever things&rsquo;: when I write &lsquo;clever code&rsquo;, that has neither comments, nor it is massaged to be Clean Code, it will cost me many times more to modify / understand in the future vs massage it a little bit.</p>

<p>For me, an example of clever code are certain bitwise operations. Even though these operations are publicly available on websites and books, you must know about them before understanding the code.</p>

<p>Another example of clever code is taking assumptions, even if they are valid. Example: always return the second element because the first one is the header</p>

<pre><code class="java">private String select(List&lt;String&gt; elements){
    return elements.get(2);
}
</code></pre>

<p>vs</p>

<pre><code class="java">private String selectFirstValidLine(List&lt;String&gt; elements){
    List&lt;String&gt; validElements = skipHeader(elements);
    return validElements.get(1);
}
</code></pre>

<h2>Open questions / other ideas</h2>

<ul>
<li>There are tests that are more important than others. Is there a tool to assign them weights and inform about which preponderation of the codebase is broken? The same (i.e., more importance) can happen for production code.</li>
<li>Is SCRUM apt for junior developers? In the sense of the increased autonomy, more decisions, more required technical skills / values, etc</li>
<li>We discussed what differentiates a project with a shorter deadline from one with a longer deadline. The consensus was: you should do tests for any kind of project, the shorter deadline project won&rsquo;t allow as much time for refactoring</li>
<li>Tests iff (i.e., if and only if) working code</li>
<li>Tests do not guarantee lack of defects</li>
<li>Bijectiveness between tests and features (production code)
</li>
</ul>

]]></content>
  </entry>
  
</feed>
